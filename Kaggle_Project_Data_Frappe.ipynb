{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "J4vwMJJObfPa",
    "outputId": "dc0856f8-6624-4ace-eb8c-a546cfa9eee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Note: using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "o7rRNY1mO7ps",
    "outputId": "e217c05b-1f45-43ca-b34b-c49d6e6752eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-12 00:34:10--  https://www.dropbox.com/s/64k2kcl8nhx22z6/clips-data-2020.zip?dl=0\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/64k2kcl8nhx22z6/clips-data-2020.zip [following]\n",
      "--2020-04-12 00:34:10--  https://www.dropbox.com/s/raw/64k2kcl8nhx22z6/clips-data-2020.zip\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com/cd/0/inline/A1qwnpyo0Y0_RK5tqBPz46orRJ2MTRDFA0Qcoq1jKBaQEpKhjU1_8i-u-hP8E7n0toV-lDJHH7OeDVBTOVcaMZ4i0VFsaIayKWskFld4v65YBqOo_XnnrQN0KMdCHw0stMI/file# [following]\n",
      "--2020-04-12 00:34:11--  https://uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com/cd/0/inline/A1qwnpyo0Y0_RK5tqBPz46orRJ2MTRDFA0Qcoq1jKBaQEpKhjU1_8i-u-hP8E7n0toV-lDJHH7OeDVBTOVcaMZ4i0VFsaIayKWskFld4v65YBqOo_XnnrQN0KMdCHw0stMI/file\n",
      "Resolving uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com (uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
      "Connecting to uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com (uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/A1qWYz-FWwMqAkTjvw64W0G1nmgJaVFW4ls8VMLszzfzZ9XRncRD4kqBEQwk7QLKHDEY_Hd11seVayPHOSzYKqzDMxCGk6lTAgsvFklckheWpIQVAplSDmflHAWGnyZsWHQaM4BBgu4SV5tbUs595S3mygRhDmGBGV3EFJh0zeKyCGp48P8u5rWKsdmk7DDC3CrzROO6O2sMwqGSp8JZmho9qRMhmBtMsgaQpYs2o0JCJvEchOlUARCwF9y1S_yEoKNz4q1Umn3q6Vmyz1pH7fUW00BISZF1bTcDVG2hLeNwrvbbihBctypD57HtfAqB7fGZoSDEYbbioqlw79HPc1Qah3yCTOEgbeV4yz9dPjRZsQ/file [following]\n",
      "--2020-04-12 00:34:11--  https://uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com/cd/0/inline2/A1qWYz-FWwMqAkTjvw64W0G1nmgJaVFW4ls8VMLszzfzZ9XRncRD4kqBEQwk7QLKHDEY_Hd11seVayPHOSzYKqzDMxCGk6lTAgsvFklckheWpIQVAplSDmflHAWGnyZsWHQaM4BBgu4SV5tbUs595S3mygRhDmGBGV3EFJh0zeKyCGp48P8u5rWKsdmk7DDC3CrzROO6O2sMwqGSp8JZmho9qRMhmBtMsgaQpYs2o0JCJvEchOlUARCwF9y1S_yEoKNz4q1Umn3q6Vmyz1pH7fUW00BISZF1bTcDVG2hLeNwrvbbihBctypD57HtfAqB7fGZoSDEYbbioqlw79HPc1Qah3yCTOEgbeV4yz9dPjRZsQ/file\n",
      "Reusing existing connection to uc244828220ecf4e2095a48ec70e.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3574845759 (3.3G) [application/zip]\n",
      "Saving to: ‘clips-data-2020.zip?dl=0’\n",
      "\n",
      "clips-data-2020.zip 100%[===================>]   3.33G  10.4MB/s    in 6m 32s  \n",
      "\n",
      "2020-04-12 00:40:44 (8.70 MB/s) - ‘clips-data-2020.zip?dl=0’ saved [3574845759/3574845759]\n",
      "\n",
      "complete\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/64k2kcl8nhx22z6/clips-data-2020.zip?dl=0\n",
    "!mv clips-data-2020.zip?dl=0 clips-data-2020.zip\n",
    "!unzip -o clips-data-2020.zip > /dev/null\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgLLDcu1igeh"
   },
   "source": [
    "Next, we build a dataframe that contains the filenames and the clip_count.  You will need to modify the paths below to match where you put train.csv and master.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OVjC5i3B8j2k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df0 = pd.read_csv(\n",
    "    '/content/drive/My Drive/KaggleProject/train.csv', \n",
    "    na_values=['NA', '?'])\n",
    "df1 = pd.read_csv(\n",
    "    '/content/drive/My Drive/KaggleProject/master.csv', \n",
    "    na_values=['NA', '?'])\n",
    "df = pd.concat([df0,df1])\n",
    "\n",
    "df['filename']=\"clips-\"+df[\"id\"].astype(str)+\".png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m2WuwUA8in-A"
   },
   "source": [
    "Separate into a training and validation (for early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kptA9LNESZBR",
    "outputId": "6c58cb54-81ed-43c8-f113-46c98fc3197a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 33750\n",
      "Validate size: 11250\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PCT = 0.75\n",
    "TRAIN_CUT = int(len(df) * TRAIN_PCT)\n",
    "\n",
    "df_train = df[0:TRAIN_CUT]\n",
    "df_validate = df[TRAIN_CUT:]\n",
    "\n",
    "print(f\"Training size: {len(df_train)}\")\n",
    "print(f\"Validate size: {len(df_validate)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "On-mz3X8iwZK"
   },
   "source": [
    "Create DataGenerators for training and validation.  This is what links the .csv with the images.  This part might take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gUitfsjtft_s",
    "outputId": "8b54b93d-ec4f-4e1a-93ba-e56234bc7faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 33750 validated image filenames.\n",
      "Found 11250 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGES_DIR = \"/content/clips\"\n",
    "\n",
    "training_datagen = ImageDataGenerator(\n",
    "  samplewise_center = True,\n",
    "  rescale = 1./255,\n",
    "  horizontal_flip=True,\n",
    "  vertical_flip=True,\n",
    "  fill_mode = 'nearest')\n",
    "\n",
    "train_generator = training_datagen.flow_from_dataframe(\n",
    "        dataframe=df_train,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"clip_count\",\n",
    "        target_size=(256, 256),\n",
    "        batch_size=16,  \n",
    "        class_mode='other')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255, samplewise_center = True)\n",
    "\n",
    "val_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_validate,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"clip_count\",\n",
    "        target_size=(256, 256),\n",
    "        class_mode='other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YcP71KtJi4KP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MhlxVGaCEjTE",
    "outputId": "b3fa5206-6da4-497f-be2b-c01055a0ee30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 125, 125, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               125960704 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 125,999,937\n",
      "Trainable params: 125,999,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "2000/2000 [==============================] - 1264s 632ms/step - loss: 12.5026 - val_loss: 4.5508\n",
      "Epoch 2/40\n",
      "2000/2000 [==============================] - 1258s 629ms/step - loss: 5.1630 - val_loss: 3.4358\n",
      "Epoch 3/40\n",
      "2000/2000 [==============================] - 1261s 631ms/step - loss: 3.6156 - val_loss: 5.5419\n",
      "Epoch 4/40\n",
      "2000/2000 [==============================] - 1249s 625ms/step - loss: 2.9131 - val_loss: 2.3890\n",
      "Epoch 5/40\n",
      "2000/2000 [==============================] - 1250s 625ms/step - loss: 2.5224 - val_loss: 1.8126\n",
      "Epoch 6/40\n",
      "2000/2000 [==============================] - 1250s 625ms/step - loss: 2.3238 - val_loss: 2.9503\n",
      "Epoch 7/40\n",
      "2000/2000 [==============================] - 1242s 621ms/step - loss: 2.1494 - val_loss: 1.7516\n",
      "Epoch 8/40\n",
      "2000/2000 [==============================] - 1242s 621ms/step - loss: 1.8382 - val_loss: 2.0147\n",
      "Epoch 9/40\n",
      "2000/2000 [==============================] - 1244s 622ms/step - loss: 1.7526 - val_loss: 1.7200\n",
      "Epoch 10/40\n",
      "2000/2000 [==============================] - 1245s 623ms/step - loss: 1.5833 - val_loss: 1.4941\n",
      "Epoch 11/40\n",
      "2000/2000 [==============================] - 1265s 633ms/step - loss: 1.5105 - val_loss: 1.4038\n",
      "Epoch 12/40\n",
      "2000/2000 [==============================] - 1254s 627ms/step - loss: 1.3822 - val_loss: 1.4975\n",
      "Epoch 13/40\n",
      "2000/2000 [==============================] - 1257s 629ms/step - loss: 1.3979 - val_loss: 2.7082\n",
      "Epoch 14/40\n",
      "2000/2000 [==============================] - 1250s 625ms/step - loss: 1.2257 - val_loss: 1.3865\n",
      "Epoch 15/40\n",
      "2000/2000 [==============================] - 1248s 624ms/step - loss: 1.2256 - val_loss: 1.6201\n",
      "Epoch 16/40\n",
      "2000/2000 [==============================] - 1251s 625ms/step - loss: 1.1445 - val_loss: 1.4074\n",
      "Epoch 17/40\n",
      "2000/2000 [==============================] - 1259s 630ms/step - loss: 1.0835 - val_loss: 3.1305\n",
      "Epoch 18/40\n",
      "2000/2000 [==============================] - 1270s 635ms/step - loss: 1.0410 - val_loss: 1.3876\n",
      "Epoch 19/40\n",
      "2000/2000 [==============================] - 1280s 640ms/step - loss: 0.9198 - val_loss: 1.3501\n",
      "Epoch 20/40\n",
      "2000/2000 [==============================] - 1290s 645ms/step - loss: 0.9011 - val_loss: 1.5932\n",
      "Epoch 21/40\n",
      "2000/2000 [==============================] - 1305s 653ms/step - loss: 0.8454 - val_loss: 1.3487\n",
      "Epoch 22/40\n",
      "2000/2000 [==============================] - 1278s 639ms/step - loss: 0.8434 - val_loss: 1.3201\n",
      "Epoch 23/40\n",
      "2000/2000 [==============================] - 1279s 639ms/step - loss: 0.7802 - val_loss: 1.3461\n",
      "Epoch 24/40\n",
      "2000/2000 [==============================] - 1259s 630ms/step - loss: 0.8081 - val_loss: 1.2949\n",
      "Epoch 25/40\n",
      "2000/2000 [==============================] - 1245s 623ms/step - loss: 0.7950 - val_loss: 1.3911\n",
      "Epoch 26/40\n",
      "2000/2000 [==============================] - 1252s 626ms/step - loss: 0.7706 - val_loss: 1.3005\n",
      "Epoch 27/40\n",
      "2000/2000 [==============================] - 1260s 630ms/step - loss: 0.6845 - val_loss: 1.4444\n",
      "Epoch 28/40\n",
      "2000/2000 [==============================] - 1250s 625ms/step - loss: 0.7105 - val_loss: 1.3557\n",
      "Epoch 29/40\n",
      "2000/2000 [==============================] - 1242s 621ms/step - loss: 0.6710 - val_loss: 1.9072\n",
      "Epoch 30/40\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6525Restoring model weights from the end of the best epoch.\n",
      "2000/2000 [==============================] - 1244s 622ms/step - loss: 0.6525 - val_loss: 1.3363\n",
      "Epoch 00030: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(256, 256, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "epoch_steps = 2000 \n",
    "validation_steps = len(df_validate)\n",
    "model.compile(loss = 'mean_squared_error', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=6, verbose=1, mode='auto',\n",
    "        restore_best_weights=True) \n",
    "history = model.fit(train_generator,  \n",
    "  steps_per_epoch = epoch_steps, \n",
    "  validation_steps = validation_steps, verbose = 1, \n",
    "  callbacks=[monitor], validation_data=val_generator, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfSV7PKYW8X1"
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iWFYuAI7W6LI",
    "outputId": "ac568e40-5e64-4511-90d3-efc98502f7e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    '/content/drive/My Drive/KaggleProject/test.csv', \n",
    "    na_values=['NA', '?'])\n",
    "\n",
    "df_test['filename']=\"clips-\"+df_test[\"id\"].astype(str)+\".png\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255, samplewise_center = True)\n",
    "\n",
    "test_generator = validation_datagen.flow_from_dataframe(\n",
    "        dataframe=df_test,\n",
    "        directory=IMAGES_DIR,\n",
    "        x_col=\"filename\",\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        target_size=(256, 256),\n",
    "        class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "n6-2QRcBc7Tc",
    "outputId": "806c594a-b27f-488d-cee9-105876f35033"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.3331058],\n",
       "       [48.81033  ],\n",
       "       [63.52879  ],\n",
       "       ...,\n",
       "       [60.25589  ],\n",
       "       [ 5.5525494],\n",
       "       [32.006855 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred = model.predict(test_generator,steps=len(df_test))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "7qzoXL5VejB9",
    "outputId": "5e8a417d-0077-4ed5-a09f-fdc79300af42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25001</td>\n",
       "      <td>2.333106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25002</td>\n",
       "      <td>48.810329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25003</td>\n",
       "      <td>63.528790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25004</td>\n",
       "      <td>2.789717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25005</td>\n",
       "      <td>44.849838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>29996</td>\n",
       "      <td>30.295801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>29997</td>\n",
       "      <td>56.102882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>29998</td>\n",
       "      <td>60.255890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>29999</td>\n",
       "      <td>5.552549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>30000</td>\n",
       "      <td>32.006855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  clip_count\n",
       "0     25001    2.333106\n",
       "1     25002   48.810329\n",
       "2     25003   63.528790\n",
       "3     25004    2.789717\n",
       "4     25005   44.849838\n",
       "...     ...         ...\n",
       "4995  29996   30.295801\n",
       "4996  29997   56.102882\n",
       "4997  29998   60.255890\n",
       "4998  29999    5.552549\n",
       "4999  30000   32.006855\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.DataFrame({'id':df_test['id'],'clip_count':pred.flatten()})\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiTMdHevooKc"
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"/content/drive/My Drive/KaggleProject/submit7.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle Project_Data Frappe.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
